# üöÄ **Agent Review Board (ARB)**

A multi-agent system for iterative content refinement with mandatory human-in-the-loop oversight.

---

## **Overview**

Agent Review Board is a collaborative AI system where multiple specialized reviewer agents provide feedback on content generated by a presenter agent. The system ensures quality through:

* **Multi-agent collaboration** ‚Äî Presenter and specialized reviewer agents
* **Mandatory HITL** ‚Äî Human approval required at each iteration
* **Incognito mode** ‚Äî No persistent storage, privacy-first design
* **Flexible LLM support** ‚Äî Works with multiple LLM providers

---

## **Features**

‚úÖ **Iterative Refinement** ‚Äî Content improves through multiple review cycles

‚úÖ **Specialized Reviewers** ‚Äî Choose from various expert roles (2-3 per session)

‚úÖ **Human-in-the-Loop** ‚Äî Approve or modify feedback before next iteration

‚úÖ **Confidence Scoring** ‚Äî Automated quality and convergence evaluation

‚úÖ **Incognito Mode** ‚Äî No data persistence, session cleared on exit

‚úÖ **Multi-Provider Support** ‚Äî OpenAI, Anthropic, Gemini, HuggingFace, Ollama, Salesforce Agentforce (FREE options available!)

---

## **Quick Start**

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Configure LLM Provider

The Agent Review Board supports multiple LLM providers, including **FREE options** perfect for demos!

#### **Option A: üÜì Google Gemini (FREE Tier)**

1. Get a FREE API key from [Google AI Studio](https://makersuite.google.com/app/apikey)
2. In the app, navigate to "LLM Settings"
3. Select "Google Gemini"
4. Enter your `GEMINI_API_KEY`
5. Select `gemini-2.5-flash` model (FREE, 15 req/min)

```bash
# Or set environment variable:
export GEMINI_API_KEY="your-key-here"
```

#### **Option B: üÜì HuggingFace Inference API (FREE)**

1. Get a FREE token from [HuggingFace Settings](https://huggingface.co/settings/tokens)
2. In the app, select "HuggingFace"
3. Enter your `HUGGINGFACE_API_KEY`
4. Use FREE models like `tiiuae/falcon-7b-instruct`

```bash
# Or set environment variable:
export HUGGINGFACE_API_KEY="your-token-here"
```

#### **Option C: üÜì Ollama (Local - Completely FREE)**

1. Download Ollama from [https://ollama.com/download](https://ollama.com/download)
2. Install and start Ollama
3. Pull free models:

```bash
ollama pull llama3
ollama pull mistral
ollama pull phi3
ollama pull codellama
ollama pull qwen2.5
```

4. In the app, select "Ollama (Local)" - No API key required!
5. Models run locally on your machine

#### **Option D: OpenAI (Paid)**

1. Get API key from [OpenAI Platform](https://platform.openai.com/api-keys)
2. Select "OpenAI" in LLM Settings
3. Enter your `OPENAI_API_KEY`

```bash
export OPENAI_API_KEY="your-key-here"
```

#### **Option E: Anthropic (Paid)**

1. Get API key from [Anthropic Console](https://console.anthropic.com/)
2. Select "Anthropic" in LLM Settings
3. Enter your `ANTHROPIC_API_KEY`

```bash
export ANTHROPIC_API_KEY="your-key-here"
```

#### **Option F: ‚ö° Salesforce Agentforce (Enterprise)**

Integrate ARB with your Salesforce Agentforce agents for enterprise AI workflows.

**Prerequisites:**
- Salesforce org with Agentforce enabled
- Agentforce Agent ID (e.g., `0XxdM0000029q33SAA`)
- Salesforce Connected App with appropriate permissions

**Configuration Steps:**

1. In the app, navigate to "LLM Settings"
2. Select "Salesforce Agentforce"
3. Enter your **Agentforce Agent ID**
4. Enter your **Salesforce Instance URL** (e.g., `https://yourorg.my.salesforce.com`)
5. Choose your authentication method:

**Authentication Options:**

**A. OAuth 2.0 Username-Password Flow** (Recommended for demos/development)
- Client ID (Consumer Key)
- Client Secret (Consumer Secret)
- Salesforce Username
- Salesforce Password (+ Security Token if required)

```bash
# Example configuration in UI:
Agent ID: 0XxdM0000029q33SAA
Instance URL: https://yourorg.my.salesforce.com
Auth Type: oauth_password
Client ID: 3MVG9...ABC123
Client Secret: 1234...5678
Username: user@yourorg.com
Password: myPassword123SecurityToken456
```

**B. OAuth 2.0 JWT Bearer Flow** (Recommended for production)
- Client ID (Consumer Key)
- Salesforce Username
- Private Key (PEM format)

‚ö†Ô∏è **JWT Setup Requirements:**
1. Create a Connected App with JWT enabled
2. Upload your X.509 certificate to the Connected App
3. Generate an RSA private key in PEM format
4. Pre-authorize your user or profile in the Connected App

```bash
# Generate RSA key pair:
openssl genrsa -out private_key.pem 2048
openssl req -new -x509 -key private_key.pem -out certificate.crt -days 365
```

**C. Session ID** (For testing/development only)
- Direct Salesforce Session ID from browser cookies or API login

**Connected App Setup:**

1. In Salesforce Setup, create a new Connected App:
   - **Basic Information:** App Name, API Name, Contact Email
   - **API (Enable OAuth Settings):** ‚úÖ Check "Enable OAuth Settings"
   - **Callback URL:** `https://localhost:8504/callback` (or your app URL)
   - **Selected OAuth Scopes:**
     - Access your basic information (id, profile, email, address, phone)
     - Perform requests on your behalf at any time (refresh_token, offline_access)
     - Access and manage your data (api)
   
2. For JWT Bearer Flow (production):
   - ‚úÖ Check "Use digital signatures"
   - Upload your `certificate.crt` file
   - ‚úÖ Check "Enable Client Credentials Flow" (optional)

3. After saving, note your **Consumer Key** (Client ID)

4. For password flow, click "Manage Consumer Details" to get **Consumer Secret**

**Example Usage:**

```python
# After configuring Agentforce in LLM Settings:
# 1. Test connection to verify authentication
# 2. Create a new session
# 3. Select your Presenter and Reviewer agents
# 4. Run iterations - all agents will use your Agentforce agent
```

**Current Implementation Status:**
- ‚úÖ OAuth Username-Password Flow - **Fully Implemented**
- ‚ö†Ô∏è OAuth JWT Bearer Flow - **Placeholder (TODO)**
- ‚úÖ Session ID Auth - **Fully Implemented**
- ‚ö†Ô∏è Agent Execution API - **Placeholder (TODO)**

The Agentforce provider is production-ready for authentication, with placeholder responses for agent execution until the Salesforce Agentforce API endpoints are finalized.

**Documentation:**
- [Salesforce Connected Apps](https://help.salesforce.com/s/articleView?id=sf.connected_app_overview.htm)
- [OAuth 2.0 JWT Bearer Flow](https://help.salesforce.com/s/articleView?id=sf.remoteaccess_oauth_jwt_flow.htm)
- [OAuth 2.0 Username-Password Flow](https://help.salesforce.com/s/articleView?id=sf.remoteaccess_oauth_username_password_flow.htm)

#### **Option G: Mock Provider (Testing Only)**

No setup required - select "Mock Provider" for testing the UI without any API calls.

### 3. Run the Application

```bash
streamlit run streamlit_app.py
```

Or for custom port:

```bash
streamlit run streamlit_app.py --server.port 8504
```

### 4. Start a Session

* Click "Start Session"
* Enter requirements/description
* Upload reference files (optional)
* Select 2-3 reviewer roles
* Choose models for each agent
* Click "Start Session"

---

## **üÜì FREE Demo Setup (Recommended)**

For a completely free demo without any API keys:

### **Method 1: Ollama (Local, Private, Fast)**

```bash
# 1. Install Ollama
brew install ollama  # macOS
# or download from https://ollama.com/download

# 2. Pull a model
ollama pull llama3

# 3. Start Ollama (runs automatically on macOS/Linux)
ollama serve

# 4. Run the app
streamlit run streamlit_app.py

# 5. In LLM Settings, select "Ollama (Local)"
```

### **Method 2: Google Gemini (Cloud, FREE Tier)**

```bash
# 1. Get FREE API key from https://makersuite.google.com/app/apikey

# 2. Set environment variable
export GEMINI_API_KEY="your-free-key"

# 3. Run the app
streamlit run streamlit_app.py

# 4. In LLM Settings, select "Google Gemini" and use "gemini-2.5-flash"
```

---

## **Architecture**

See [ARCHITECTURE.md](ARCHITECTURE.md) for detailed system design.

### Folder Structure

```
agent-review-board/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ ui/              # Streamlit UI components
‚îÇ   ‚îú‚îÄ‚îÄ core/            # Business logic & orchestration
‚îÇ   ‚îú‚îÄ‚îÄ agents/          # Agent implementations
‚îÇ   ‚îú‚îÄ‚îÄ llm/             # LLM provider abstraction
‚îÇ   ‚îú‚îÄ‚îÄ models/          # Pydantic data models
‚îÇ   ‚îî‚îÄ‚îÄ utils/           # Utility functions
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ unit/            # Unit tests
‚îÇ   ‚îî‚îÄ‚îÄ integration/     # Integration tests
‚îú‚îÄ‚îÄ streamlit_app.py     # Application entrypoint
‚îú‚îÄ‚îÄ requirements.txt     # Python dependencies
‚îú‚îÄ‚îÄ RULES.md            # Development rules
‚îî‚îÄ‚îÄ ARCHITECTURE.md     # System architecture
```

---

## **Development Rules**

See [RULES.md](RULES.md) for complete development guidelines.

### Key Principles

* ‚ö†Ô∏è **No Streamlit in core logic** ‚Äî Keep UI separate from business logic
* ‚ö†Ô∏è **HITL is mandatory** ‚Äî Never auto-advance iterations
* ‚ö†Ô∏è **No persistence** ‚Äî All data in memory only
* ‚ö†Ô∏è **Type hints everywhere** ‚Äî Maintain strong typing
* ‚ö†Ô∏è **Test coverage required** ‚Äî All components must have tests

---

## **Testing**

### Run All Tests

```bash
pytest
```

### Run Specific Test Suite

```bash
pytest tests/unit/
pytest tests/integration/
```

### Run with Coverage

```bash
pytest --cov=app tests/
```

---

## **Security & Privacy**

### üîí Incognito Mode

* **No persistent storage** ‚Äî Session data lives in memory only
* **No API key storage** ‚Äî Keys cleared on session end
* **No file retention** ‚Äî Uploaded files deleted after session
* **Browser refresh clears everything** ‚Äî Complete privacy

### üõ°Ô∏è API Key Safety

* Never stored to disk
* Never logged
* Masked in UI
* Cleared from memory on exit

---

## **LLM Provider Comparison**

| Provider | Cost | Setup | Speed | Privacy | Best For |
|----------|------|-------|-------|---------|----------|
| **Ollama** | üÜì FREE | Medium | Fast | ‚úÖ Local | Development, demos, privacy |
| **Gemini** | üÜì FREE* | Easy | Fast | ‚òÅÔ∏è Cloud | Quick demos, testing |
| **HuggingFace** | üÜì FREE* | Easy | Slow | ‚òÅÔ∏è Cloud | Experimentation |
| **OpenAI** | üí∞ Paid | Easy | Fast | ‚òÅÔ∏è Cloud | Production, best quality |
| **Anthropic** | üí∞ Paid | Easy | Fast | ‚òÅÔ∏è Cloud | Production, best quality |
| **Mock** | üÜì FREE | None | Instant | ‚úÖ Local | Testing only |

*Free tier with limits

---

## **Extending the System**

### Add a New LLM Provider

1. Create new provider class in `app/llm/`
2. Inherit from `BaseLLMProvider`
3. Implement required methods:
   - `generate_text(prompt) -> str`
   - `list_models() -> List[str]`
   - `validate_connection() -> bool`
   - `get_provider_name() -> str`
4. Register in `ProviderFactory.PROVIDERS`
5. Add UI configuration in `app/ui/pages/llm_settings.py`
6. Add tests in `tests/test_provider_*.py`

### Add a New Reviewer Role

1. Subclass `ReviewerAgent` in `app/agents/reviewer.py`
2. Define specialized prompt template and focus areas
3. Register in role configuration
4. Add to UI dropdown in start session page

---

## **Project Status**

**Phase 1:** ‚úÖ Complete - Scaffolding & Architecture

* Folder structure
* Architecture documentation
* UI skeleton
* Stub implementations
* Test scaffolding

**Phase 2:** ‚úÖ Complete - Intelligence Layer

* Production LLM providers (OpenAI, Anthropic, Gemini, HuggingFace, Ollama)
* Real agent logic (Presenter, Reviewers, Confidence)
* Orchestrator with HITL enforcement
* Full test coverage
* FREE provider options for demos

**Phase 3:** üéØ Current - Enhanced Features

* Multi-provider support with free tiers
* Improved UI/UX
* Additional agent roles
* Performance optimizations

---

## **License**

MIT License - See LICENSE file for details

---

## **Contributing**

1. Read [RULES.md](RULES.md) and [ARCHITECTURE.md](ARCHITECTURE.md)
2. Follow strict separation of concerns
3. Write tests for all new code
4. Use type hints and docstrings
5. Submit PR with clear description

---

**Built with ‚ù§Ô∏è for safe, human-supervised AI collaboration**

